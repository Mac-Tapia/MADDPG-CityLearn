# MADDPG CityLearn - Instrucciones para Agentes IA

## Descripción del Proyecto
**Tesis**: Aprendizaje por Refuerzo Profundo Multi-Agente (MADDPG) para control de flexibilidad energética en comunidades de edificios inteligentes. Usa Entrenamiento Centralizado, Ejecución Descentralizada (CTDE)—cada edificio es un agente con su propio Actor; el entrenamiento usa un Crítico centralizado.

**Dataset**: `citylearn_challenge_2022_phase_all_plus_evs` (EVs, solar FV, baterías, HVAC, ACS).

## Arquitectura

```
src/maddpg_tesis/
├── maddpg/           # Implementación central de RL
│   ├── maddpg.py     # Orquestador (agentes, replay buffer, bucle de entrenamiento)
│   ├── agent.py      # DDPGAgent: pares Actor/Crítico + redes target
│   ├── policies.py   # Redes neuronales: Actor(obs→acción), Crítico(obs_global+acciones→Q)
│   ├── replay_buffer.py
│   └── noise.py      # GaussianNoiseScheduler para exploración
├── envs/             # Wrapper CityLearnMultiAgentEnv
├── api/              # Servicio FastAPI (deps.py usa @lru_cache singleton)
├── core/             # Dataclasses de config, utils (get_device, soft_update, to_tensor)
└── models/           # loader.py - REQUERIDO para cargar checkpoints
```

**Flujo de Datos**: `CityLearnMultiAgentEnv` → `MADDPG.select_actions()` → `env.step()` → `ReplayBuffer` → `MADDPG.update()`

## Invariantes Críticos

| Elemento | Restricción | Ejemplo |
|----------|-------------|---------|
| Observaciones | `(n_agents, obs_dim)` numpy | `obs.shape == (5, 28)` para 5 edificios |
| Acciones | `(n_agents, action_dim)` en `[-1, 1]` | Recortado con `np.clip(..., -1.0, 1.0)` |
| Recompensas | `(n_agents,)` por agente | Una recompensa por edificio |
| `central_agent` | **SIEMPRE `False`** | `CityLearnMultiAgentEnv(..., central_agent=False)` |

## Sistema de Configuración

Todos los hiperparámetros en `configs/citylearn_maddpg.yaml`. **Nunca hardcodear**:
```python
from maddpg_tesis.core.config import load_config
cfg = load_config()  # Retorna ProjectConfig con secciones env, maddpg, training, api
# Acceso: cfg.maddpg.gamma, cfg.training.val_every, cfg.env.reward_weights
```

Secciones clave del config:
- `env.reward_weights`: `{cost: 1.0, peak: 0.5, co2: 0.3, discomfort: 0.2}` — KPIs de flexibilidad de la tesis
- `maddpg.update_after`: Esperar N pasos antes de entrenar (default: 8760 = 1 episodio/año completo)
- `training.val_every`: Frecuencia de validación para early stopping

## Comandos de Desarrollo

```powershell
# SIEMPRE ejecutar desde el directorio maddpg_citylearn/ (las rutas de config asumen este CWD)
cd maddpg_citylearn

# Entrenamiento
python -m maddpg_tesis.scripts.train_citylearn

# Tests (omitir carga de modelo)
$env:SKIP_MODEL_LOAD_FOR_TESTS="1"; pytest -q

# Servidor API
uvicorn maddpg_tesis.api.main:app --host 0.0.0.0 --port 8000

# Build Docker (GPU con CUDA 12.1)
docker build -t maddpg-citylearn .
```

## Patrón de Guardar/Cargar Modelo

```python
# Guardar (atómico via archivo temporal)
maddpg.save("models/citylearn_maddpg/maddpg.pt")

# Cargar - SIEMPRE usar loader.py (reconstruye MADDPG desde config guardado)
from maddpg_tesis.models.loader import load_maddpg
model = load_maddpg("models/citylearn_maddpg/maddpg.pt", device="cuda")
# ❌ NUNCA: torch.load("maddpg.pt") directamente
```

**Checkpoints**: `maddpg.pt` (mejor train), `maddpg_val_best.pt` (mejor val), `maddpg_last.pt` (último)

## Estrategia de Testing

- `conftest.py` establece `SKIP_MODEL_LOAD_FOR_TESTS=1` y agrega `src/` al path
- Testear componentes aislados: `test_maddpg.py` prueba Actor, Critic, ReplayBuffer sin env CityLearn
- Tests de API usan `DummyModel` cuando la variable de entorno está activa (ver `deps.py`)

## Errores Comunes

1. **CWD incorrecto**: Los scripts esperan `maddpg_citylearn/` como directorio de trabajo
2. **Errores de shape**: Siempre verificar formato `(n_agents, dim)`; depurar con `print(obs.shape)`
3. **Instalación CityLearn**: Debe usar `pip install citylearn==2.5.0 --no-deps` por conflictos
4. **Mismatch de device**: Usar `core.utils.get_device()` y `to_tensor(arr, device)`
5. **Ruido en inferencia**: Usar `noise=False` en `select_actions()` para validación/producción
6. **Duración de episodio**: Los episodios de CityLearn son 8760 pasos (1 año horario); el entrenamiento es lento

## Contrato de API

| Endpoint | Método | Propósito |
|----------|--------|-----------|
| `/health` | GET | Probe de liveness |
| `/ready` | GET | Readiness (verifica modelo cargado) |
| `/metrics` | GET | Info del modelo + uptime (compatible Prometheus) |
| `/predict` | POST | Inferencia: `{"observations": [[...], [...]]}` → `{"actions": [[...], [...]]}`|
| `/dashboard` | GET | Dashboard de monitoreo HTML |

## Despliegue

- **Local**: Comando `uvicorn` arriba
- **Docker**: Build multi-stage con CUDA 12.1, usuario non-root (`appuser`)
- **Kubernetes**: Manifiestos en `kubernetes/` con soporte GPU, HPA, monitoreo Prometheus
